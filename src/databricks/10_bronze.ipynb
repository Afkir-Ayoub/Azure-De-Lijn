{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c75bb28c-e3a7-4f5f-8806-7dc90a9abdd3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Bronze Layer Ingestion\n",
    "\n",
    "This notebook ingests raw data from two sources and lands it in Bronze Delta tables.\n",
    "\n",
    "- **1. Real-time Vehicle Updates**: A continuous stream from Azue Event Hubs.\n",
    "- **2. Static GTFS Data**: A daily batch ZIP file from ADLS Gen2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "79f24176-9940-4f76-805d-e8dd476c3aa6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "from pyspark.sql import functions as F\n",
    "import io\n",
    "import zipfile\n",
    "import os\n",
    "import shutil\n",
    "from pyspark.sql.functions import col, length, from_json, explode, from_unixtime\n",
    "from pyspark.sql.types import StructType, StructField, MapType, StringType, IntegerType, DoubleType, LongType, DoubleType, ArrayType, TimestampType, BooleanType, FloatType\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cde408ae-0d1f-44b5-97f5-d7526c9a25d6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define widgets to accept parameters via DB job\n",
    "dbutils.widgets.text(\"secret_scope_name\", \"delijn-secrets\", \"Secret Scope Name\")\n",
    "dbutils.widgets.text(\"eh_conn_str_key\", \"eh-conn-str\", \"Event Hub Connection String Key\")\n",
    "\n",
    "# Define file paths\n",
    "SILVER_PATH = \"/mnt/silver/\"\n",
    "\n",
    "REALTIME_TABLE_NAME = \"realtime_trips\"\n",
    "BRONZE_REALTIME_CHECKPOINT = f\"/mnt/bronze/checkpoints/{REALTIME_TABLE_NAME}\"\n",
    "\n",
    "BRONZE_GTFS_PATH = \"/mnt/bronze/gtfs/gtfs_transit.zip\"\n",
    "UNZIPPED_GTFS_PATH = \"/mnt/bronze/gtfs/gtfs_unzipped/\"\n",
    "TEMP_ZIP_PATH = \"/tmp/gtfs_transit.zip\"\n",
    "TEMP_UNZIPPED_PATH = \"/tmp/gtfs_unzipped/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "481cbbcf-9c49-4c55-a20c-8f31fc83d5f9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Event body schema\n",
    "time_schema = StructType([\n",
    "    StructField(\"delay\", LongType(), True),\n",
    "    StructField(\"time\", LongType(), True)\n",
    "])\n",
    "\n",
    "stop_time_update_schema = StructType([\n",
    "    StructField(\"stopId\", StringType(), True),\n",
    "    StructField(\"arrival\", time_schema, True),\n",
    "    StructField(\"departure\", time_schema, True),\n",
    "    StructField(\"stopSequence\", LongType(), True)\n",
    "])\n",
    "\n",
    "event_body_schema = StructType([\n",
    "    StructField(\"id\", StringType(), True),\n",
    "    StructField(\"tripUpdate\", StructType([\n",
    "        StructField(\"trip\", StructType([\n",
    "            StructField(\"tripId\", StringType(), True),\n",
    "            StructField(\"startDate\", StringType(), True)\n",
    "        ]), True),\n",
    "        StructField(\"stopTimeUpdate\", ArrayType(stop_time_update_schema), True),\n",
    "        StructField(\"vehicle\", StructType([\n",
    "             StructField(\"id\", StringType(), True)\n",
    "        ]), True),\n",
    "        StructField(\"timestamp\", LongType(), True)\n",
    "    ]), True),\n",
    "    StructField(\"vehicle\", StructType([\n",
    "        StructField(\"vehicle\", StructType([\n",
    "             StructField(\"id\", StringType(), True)\n",
    "        ]), True),\n",
    "        StructField(\"trip\", StructType([\n",
    "            StructField(\"tripId\", StringType(), True)\n",
    "        ]), True),\n",
    "        StructField(\"position\", StructType([\n",
    "            StructField(\"latitude\", DoubleType(), True),\n",
    "            StructField(\"longitude\", DoubleType(), True)\n",
    "        ]), True),\n",
    "        StructField(\"timestamp\", LongType(), True)\n",
    "    ]), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "25404aae-c3d3-4bb0-af01-430b8822f301",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 1. Real-Time Data Ingestion (From Event Hubs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5edd7e8b-2572-467c-a5c6-328a3c533efc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load RT stream\n",
    "scope = dbutils.widgets.get(\"secret_scope_name\")\n",
    "key = dbutils.widgets.get(\"eh_conn_str_key\")\n",
    "EH_CONN_STR = dbutils.secrets.get(scope=scope, key=key)\n",
    "\n",
    "eh_conf = {\n",
    "  'eventhubs.connectionString': sc._jvm.org.apache.spark.eventhubs.EventHubsUtils.encrypt(EH_CONN_STR),\n",
    "  'eventhubs.consumerGroup': '$Default',\n",
    "  'eventhubs.eventPosition': 'earliestEventPosition'\n",
    "}\n",
    "\n",
    "df_stream_raw = (\n",
    "  spark.readStream\n",
    "    .format(\"eventhubs\")\n",
    "    .options(**eh_conf)\n",
    "    .load()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ba2a20e8-7fc2-420b-a2bb-11638e270748",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Transform RT data\n",
    "parsed_stream = (\n",
    "    df_stream_raw\n",
    "    .withColumn(\"body\", col(\"body\").cast(StringType()))\n",
    "    .withColumn(\"event\", from_json(col(\"body\"), event_body_schema))\n",
    "    .select(\n",
    "        col(\"event.id\").alias(\"update_id\"),\n",
    "        col(\"event.tripUpdate.trip.tripId\").alias(\"trip_id\"),\n",
    "        col(\"event.tripUpdate.trip.startDate\").alias(\"trip_start_date\"),\n",
    "        col(\"event.tripUpdate.vehicle.id\").alias(\"vehicle_id\"),\n",
    "        col(\"event.vehicle.position.latitude\").alias(\"latitude\"),\n",
    "        col(\"event.vehicle.position.longitude\").alias(\"longitude\"),\n",
    "        from_unixtime(col(\"event.tripUpdate.timestamp\")).cast(TimestampType()).alias(\"event_timestamp\"),\n",
    "        explode(\"event.tripUpdate.stopTimeUpdate\").alias(\"stop_update\") # Explode the array\n",
    "    )\n",
    ")\n",
    "\n",
    "final_stream = parsed_stream.select(\n",
    "    \"update_id\",\n",
    "    \"trip_id\",\n",
    "    \"trip_start_date\",\n",
    "    \"vehicle_id\",\n",
    "    \"latitude\",\n",
    "    \"longitude\",\n",
    "    \"event_timestamp\",\n",
    "    col(\"stop_update.stopId\").alias(\"stop_id\"),\n",
    "    col(\"stop_update.stopSequence\").alias(\"stop_sequence\"),\n",
    "    col(\"stop_update.departure.delay\").alias(\"departure_delay_seconds\"),\n",
    "    from_unixtime(col(\"stop_update.departure.time\")).cast(TimestampType()).alias(\"departure_time\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "84a103fa-1f2e-4a8c-8da0-888e00042d55",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<pyspark.sql.streaming.query.StreamingQuery at 0x7f7ba91e28d0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write stream to silver layer\n",
    "(\n",
    "    final_stream.writeStream\n",
    "    .format(\"delta\")\n",
    "    .outputMode(\"append\")\n",
    "    .option(\"checkpointLocation\", BRONZE_REALTIME_CHECKPOINT)\n",
    "    .trigger(availableNow=True) # process all available data in a micro-batch; more efficient for scheduled jobs\n",
    "    .start(f'{SILVER_PATH}/{REALTIME_TABLE_NAME}')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7a5c5815-3bdb-4be5-9d40-554cb6c4cc75",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 2. Static GTFS Batch Data Ingestion (From ADLS Gen2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aaf6a392-142d-4006-9742-1e3ef98847e4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean up\n",
    "if os.path.exists(TEMP_ZIP_PATH):\n",
    "    os.remove(TEMP_ZIP_PATH)\n",
    "\n",
    "if os.path.exists(TEMP_UNZIPPED_PATH):\n",
    "    shutil.rmtree(TEMP_UNZIPPED_PATH)\n",
    "\n",
    "dbutils.fs.rm(UNZIPPED_GTFS_PATH, recurse=True)\n",
    "dbutils.fs.mkdirs(UNZIPPED_GTFS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0b533131-450f-4ede-9c8c-3985d79c8c48",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Copy ZIP to local\n",
    "dbutils.fs.cp(BRONZE_GTFS_PATH, f\"file:{TEMP_ZIP_PATH}\")\n",
    "\n",
    "try:\n",
    "    with zipfile.ZipFile(TEMP_ZIP_PATH, 'r') as zip_ref:\n",
    "        os.makedirs(TEMP_UNZIPPED_PATH, exist_ok=True)\n",
    "        zip_ref.extractall(TEMP_UNZIPPED_PATH)\n",
    "\n",
    "    # Copy unzipped to DBFS\n",
    "    for file_name in os.listdir(TEMP_UNZIPPED_PATH):\n",
    "        source_path = f\"file://{TEMP_UNZIPPED_PATH}{file_name}\"\n",
    "        target_path = f\"{UNZIPPED_GTFS_PATH}{file_name}\"\n",
    "        dbutils.fs.cp(source_path, target_path)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during unzipping.\")\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5dc80eff-6cc5-4287-a4d4-40167991239e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Txt files to process\n",
    "files_to_process = {\n",
    "    \"stops.txt\": {\n",
    "        \"schema\": StructType([\n",
    "            StructField(\"stop_id\", StringType(), True),\n",
    "            StructField(\"stop_code\", StringType(), True),\n",
    "            StructField(\"stop_name\", StringType(), True),\n",
    "            StructField(\"stop_lat\", DoubleType(), True),\n",
    "            StructField(\"stop_lon\", DoubleType(), True),\n",
    "            StructField(\"stop_url\", StringType(), True),\n",
    "            StructField(\"wheelchair_boarding\", BooleanType(), True)\n",
    "        ]),\n",
    "        \"silver_table_name\": \"stops\",\n",
    "        \"transform_func\": lambda df: df.select(\n",
    "            col(\"stop_id\"), col(\"stop_name\"), col(\"stop_code\"),\n",
    "            col(\"stop_lat\").alias(\"latitude\"), col(\"stop_lon\").alias(\"longitude\"),\n",
    "            col(\"wheelchair_boarding\")\n",
    "        )\n",
    "    },\n",
    "    \"routes.txt\": {\n",
    "        \"schema\": StructType([\n",
    "            StructField(\"route_id\", StringType(), True),\n",
    "            StructField(\"agency_id\", StringType(), True),\n",
    "            StructField(\"route_short_name\", StringType(), True),\n",
    "            StructField(\"route_long_name\", StringType(), True),\n",
    "            StructField(\"route_desc\", StringType(), True),\n",
    "            StructField(\"route_type\", IntegerType(), True),\n",
    "            StructField(\"route_url\", StringType(), True),\n",
    "            StructField(\"route_color\", StringType(), True),\n",
    "            StructField(\"route_text_color\", StringType(), True)\n",
    "        ]),\n",
    "        \"silver_table_name\": \"routes\",\n",
    "        \"transform_func\": lambda df: df  # Keep as is\n",
    "    },\n",
    "    \"trips.txt\": {\n",
    "        \"schema\": StructType([\n",
    "            StructField(\"route_id\", StringType(), True),\n",
    "            StructField(\"service_id\", StringType(), True),\n",
    "            StructField(\"trip_id\", StringType(), True),\n",
    "            StructField(\"trip_headsign\", StringType(), True),\n",
    "            StructField(\"trip_short_name\", StringType(), True),\n",
    "            StructField(\"direction_id\", IntegerType(), True),\n",
    "            StructField(\"block_id\", StringType(), True),\n",
    "            StructField(\"shape_id\", StringType(), True)\n",
    "        ]),\n",
    "        \"silver_table_name\": \"trips\",\n",
    "        \"transform_func\": lambda df: df\n",
    "    },\n",
    "    \"stop_times.txt\": {\n",
    "        \"schema\": StructType([\n",
    "            StructField(\"trip_id\", StringType(), True),\n",
    "            StructField(\"arrival_time\", StringType(), True),\n",
    "            StructField(\"departure_time\", StringType(), True),\n",
    "            StructField(\"stop_id\", StringType(), True),\n",
    "            StructField(\"stop_sequence\", IntegerType(), True),\n",
    "            StructField(\"pickup_type\", IntegerType(), True),\n",
    "            StructField(\"drop_off_type\", IntegerType(), True)\n",
    "        ]),\n",
    "        \"silver_table_name\": \"stop_times\",\n",
    "        \"transform_func\": lambda df: df\n",
    "    },\n",
    "    \"calendar_dates.txt\": {\n",
    "        \"schema\": StructType([\n",
    "            StructField(\"service_id\", StringType(), True),\n",
    "            StructField(\"date\", IntegerType(), True), # YYYYMMDD\n",
    "            StructField(\"exception_type\", IntegerType(), True)\n",
    "        ]),\n",
    "        \"silver_table_name\": \"calendar_dates\",\n",
    "        \"transform_func\": lambda df: df\n",
    "    },\n",
    "    \"shapes.txt\": {\n",
    "        \"schema\": StructType([\n",
    "            StructField(\"shape_id\", StringType(), True),\n",
    "            StructField(\"shape_pt_lat\", DoubleType(), True),\n",
    "            StructField(\"shape_pt_lon\", DoubleType(), True),\n",
    "            StructField(\"shape_pt_sequence\", IntegerType(), True),\n",
    "            StructField(\"shape_dist_traveled\", FloatType(), True)\n",
    "        ]),\n",
    "        \"silver_table_name\": \"shapes\",\n",
    "        \"transform_func\": lambda df: df\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5edeed38-5211-4046-b14d-269a65721259",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created silver table: stops\nSuccessfully created silver table: routes\nSuccessfully created silver table: trips\nSuccessfully created silver table: stop_times\nSuccessfully created silver table: calendar_dates\nSuccessfully created silver table: shapes\n\n--- All static files processed successfully! ---\n"
     ]
    }
   ],
   "source": [
    "# Load & process each file\n",
    "for file_name, config in files_to_process.items():\n",
    "    raw_path = f\"{UNZIPPED_GTFS_PATH}/{file_name}\"\n",
    "    silver_path = f\"{SILVER_PATH}/{config['silver_table_name']}\"\n",
    "\n",
    "    raw_df = (\n",
    "        spark.read\n",
    "        .format(\"csv\")\n",
    "        .option(\"header\", \"true\")\n",
    "        .schema(config['schema'])\n",
    "        .load(raw_path)\n",
    "    )\n",
    "\n",
    "    transformed_df = config['transform_func'](raw_df)\n",
    "\n",
    "    (\n",
    "        transformed_df.write\n",
    "        .format(\"delta\")\n",
    "        .mode(\"overwrite\")\n",
    "        .option(\"overwriteSchema\", \"true\")\n",
    "        .save(silver_path)\n",
    "    )\n",
    "    \n",
    "    print(f\"Successfully created silver table: {config['silver_table_name']}\")\n",
    "\n",
    "print(\"\\n--- All static files processed successfully! ---\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 6249951992273494,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "10_bronze",
   "widgets": {
    "eh_conn_str_key": {
     "currentValue": "eh-conn-str",
     "nuid": "daa2689d-985e-472c-9874-6a29fb6fd9f2",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "eh-conn-str",
      "label": "Event Hub Connection String Key",
      "name": "eh_conn_str_key",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "eh-conn-str",
      "label": "Event Hub Connection String Key",
      "name": "eh_conn_str_key",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "secret_scope_name": {
     "currentValue": "delijn-secrets",
     "nuid": "f59fb5e4-b69e-42c8-9f9c-330071ff9e0e",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "delijn-secrets",
      "label": "Secret Scope Name",
      "name": "secret_scope_name",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "delijn-secrets",
      "label": "Secret Scope Name",
      "name": "secret_scope_name",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
